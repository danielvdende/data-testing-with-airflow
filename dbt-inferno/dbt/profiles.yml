transactions:
  target: local
  outputs:
    local:
      type: spark
      host: localhost
      method: session
      schema: bank
      server_side_parameters:
        "spark.databricks.delta.schema.autoMerge.enabled": "True"
        "spark.sql.warehouse.dir": "/opt/airflow/spark-warehouse"
        "spark.sql.parquet.compression.codec": "gzip"
        "spark.hadoop.javax.jdo.option.ConnectionURL": "jdbc:derby:;databaseName=/opt/airflow/metastore_db;create=true"
      #      threads: 1
#      keepalives_idle: 0 # default 0, indicating the system default
      # search_path: [optional, override the default postgres search_path]
      # role: [optional, set the role dbt assumes when executing queries]
      # sslmode: [optional, set the sslmode used to connect to the database]
    airflow:
      type: postgres
      host: postgresdb
      user: postgres
      pass: p@ssw0rd
      port: 5432
      dbname: postgresdb
      schema: public
      threads: 1
      keepalives_idle: 0 # default 0, indicating the system default
      # search_path: [optional, override the default postgres search_path]
      # role: [optional, set the role dbt assumes when executing queries]
      # sslmode: [optional, set the sslmode used to connect to the database]

